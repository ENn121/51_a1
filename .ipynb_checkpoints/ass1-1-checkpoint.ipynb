{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104830\n",
      "104830\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "f1 = open('/Users/enn/Desktop/sml/assignment1/data/train.txt', 'r')\n",
    "\n",
    "xdata = []\n",
    "\n",
    "x1 = []\n",
    "x2 = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "ydata = []\n",
    "k = []\n",
    "n = []\n",
    "l = []\n",
    "\n",
    "for lines in f1.readlines():\n",
    "    lines = lines.replace('\\n', '')\n",
    "    item = lines.replace('\\t', ' ').split(' ')\n",
    "    l.append(item)\n",
    "\n",
    "    for i in range(len(item)):\n",
    "        if (i > 0):\n",
    "            x1.append([item[0], item[i]])\n",
    "            y1.append(1)\n",
    "m = l  \n",
    "for i in l:\n",
    "    for j in m:\n",
    "        k = [x for x in i if x in j]\n",
    "        if k == []:\n",
    "            n.append([i[0], j[0]])\n",
    "            \n",
    "for p in range(len(n)):\n",
    "    if p % 300 == 0:\n",
    "        x2.append(n[p])\n",
    "        y2.append(0)\n",
    "#print(len(x2))\n",
    "#print(x2)\n",
    "xdata = x1 + x2\n",
    "print(len(xdata))\n",
    "ydata = y1 + y2\n",
    "print(len(ydata))\n",
    "\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "[[0.000e+00 2.860e+03]\n",
      " [0.000e+00 3.117e+03]\n",
      " [1.000e+00 3.180e+02]\n",
      " ...\n",
      " [4.084e+03 3.370e+03]\n",
      " [4.084e+03 3.678e+03]\n",
      " [4.084e+03 3.992e+03]]\n",
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "batch_size = 1000\n",
    "#how many batches\n",
    "n_batch = len(xdata) // batch_size + 1\n",
    "print(n_batch)\n",
    "xdata = np.asarray(xdata, dtype=np.float32)\n",
    "ydata = np.asarray(ydata, dtype=np.float32)\n",
    "print(xdata)\n",
    "print(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104830\n",
      "104830\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx = np.arange(0 , len(train))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "x_train = [train[i] for i in idx]\n",
    "y_train = [y[i] for i in idx]\n",
    "#print(x_train)\n",
    "#print(y_train)\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 4.021e+03]\n",
      " [2.000e+00 3.795e+03]\n",
      " [3.000e+00 1.627e+03]\n",
      " ...\n",
      " [3.946e+03 3.956e+03]\n",
      " [3.956e+03 3.969e+03]\n",
      " [4.024e+03 4.059e+03]]\n"
     ]
    }
   ],
   "source": [
    "f2 = open('/Users/enn/Desktop/sml/assignment1/data/test-public.csv', 'r')\n",
    "test = f2.readlines()\n",
    "testx = []\n",
    "#print(test)\n",
    "for line in test[1:]:\n",
    "    line = line.strip('\\n')\n",
    "    linelist = line.split(',')\n",
    "    testx.append(linelist[1:])\n",
    "testx = np.asarray(testx, dtype=np.float32)\n",
    "print(testx)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f3 = open('/Users/enn/Desktop/sml/assignment1/data/nodes.json', 'r')\n",
    "load_dict = json.load(f3)\n",
    "print(load_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-552cd876a006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m trn_data, testfile, trn_classes, test_classes = train_test_split(\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "trn_data, testfile, trn_classes, test_classes = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    test_size = 0.3,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(testfile)\n",
    "print (accuracy_score(test_classes,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Initialize\n",
    "import Evaluation_Indicators.AUC\n",
    "\n",
    "Matrix_similarity = similarity_indicators.Salton.Salton(x_train)\n",
    "        Evaluation_Indicators.AUC.Calculation_AUC(x_train, testx, Matrix_similarity, MaxNodeNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
